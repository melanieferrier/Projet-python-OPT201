{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical project in Python\n",
    "\n",
    "We will consider the problem of finding the static equilibrium of a chain formed by rigid bars in 2D.\n",
    "This will be found via an optimization problem with equality constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Python function that given $z$ as an imput, returns :\n",
    "\n",
    "$$\n",
    "c(z) = (c_1 (z) , \\ldots , c_{N+1} (z) ) = (l_{i}(x, y)^{2}-L^{2} = \\bigl(  (x_{i}-x_{i-1})^{2}+(y_{i}-y_{i-1})^{2}-L^{2} \\, , \\, i \\in [ 1 , \\ldots , N+1 ] \\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(z):\n",
    "    N=np.len(z)/2\n",
    "    x=z[0:N:1]\n",
    "    y=z[N:2*N:1]\n",
    "    c=np.zeros((N+1,1))\n",
    "    c[0] = (x[0])**2+(y[0])**2 - L**2\n",
    "    for i in range(1,N)\n",
    "        l=(x[i]-x[i-1])**2+(y[i]-y[i-1])**2 - L**2\n",
    "    c[N+1] = (a-x[N-1])**2+(b-y[N-1])**2 - L**2\n",
    "    return c\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Python function that given $z$ as an imput, return $\\sum_i y_i$.\n",
    "\n",
    "To do so, we compute a $e = (0 , \\ldots , 0 , 1 , \\ldots , 1)$ $2n$-array, and we comput the dot product of $e . z$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e(z):\n",
    "    N=np.len(z)/2\n",
    "    e=np.zeros(2*N)\n",
    "    e[N:2*N:1]=np.ones(N)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(z):\n",
    "    return np.dot(e(z), z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Python function that returns the lagrangian of the systeme, given $z$ and $\\lambda$ as an imput.\n",
    "\n",
    "To do so we write the Lagrangian as :\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(z, \\lambda)=e^{\\top} z+\\lambda^{\\top} c(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(z,labda):\n",
    "    e=e(z)\n",
    "    return np.dot(np.transpose(e),z) + np.dot(np.transpose(labda),c(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Python function, that given $z$, $\\lambda$ as an imput, yields $\\nabla_z \\mathcal{L}(z, \\lambda)$.\n",
    "\n",
    "As shown in the report : \n",
    "$$\n",
    "\\nabla_{z} \\mathcal{L}(z, \\lambda)=e+\\nabla_{z}^{\\top} c(z) \\lambda \\in \\mathbf{R}^{2 N}\n",
    "$$\n",
    "\n",
    "where the gradient matrix of c (transpose of the Jacobian matrix) is :\n",
    "$$\n",
    "\\nabla_{z}^{\\top} c(z)= 2\\begin{bmatrix}\n",
    "x_1 & -(x_2 - x_1) & 0 & \\cdots & 0 \\\\\n",
    "0 & (x_2 - x_1) & -(x_3 - x_2) & \\cdots & 0 \\\\\n",
    "\\\\\n",
    "\\vdots & & \\ddots & \\ddots & \\vdots \\\\\n",
    "& & & & 0\\\\\n",
    "0 & \\cdots & 0 & (x_N - x_{N-1}) & -(x_N - a)\\\\\n",
    "\\hline y_1 & -(y_2 - y_1) & 0 & \\cdots & 0 \\\\\n",
    "0 & (y_2 - y_1) & -(y_3 - y_2) & \\cdots & 0 \\\\\n",
    "\\\\\n",
    "\\vdots & & \\ddots & \\ddots & \\vdots \\\\\n",
    "& & & & 0\\\\\n",
    "0 & \\cdots & 0 & (y_N - y_{N-1}) & -(y_N - a)\\\\\n",
    "\\end{bmatrix} \\in \\mathbf{R}^{2 N \\times N+1}\n",
    "$$\n",
    "\n",
    "First lets compute this gradient matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradc(z):\n",
    "    N=np.len(z)/2\n",
    "    cjac=np.zeros(2*N, N+1)\n",
    "    \n",
    "    gradc[0,0] = 2*z[0]\n",
    "    gradc[N,0] = 2*z[N]\n",
    "    gradc[N-1,N] = 2*(z[N-1]-a)\n",
    "    gradc[2*n-1,N] = 2*(z[N-1]-b)\n",
    "    \n",
    "    for j in range(1,N):\n",
    "        temp = 2*(z[j]-z[j-1])\n",
    "        gradc[j,j-1] = -temp\n",
    "        gradc[j,j] = temp\n",
    "        temp = 2*(z[N+j]-z[N+j-1])\n",
    "        gradc[j,N+j-1] = -temp\n",
    "        gradc[j,N+j] = temp\n",
    "    return gradc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deduce the gradient of the Lagrangian by the quick vectorial calculation above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradlag(z,labda):\n",
    "    e=e(z)\n",
    "    gradc = gradc(z)\n",
    "    return e + np.dot(gradc,labda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function also check that the derivatives are correct, by checking that :\n",
    "$$\n",
    "\\frac{\\left\\|c(z+\\delta)-c(z)-\\nabla_{z} c(z) \\delta\\right\\|}{\\|\\delta\\|} \\leq 0.01\n",
    "$$\n",
    "\n",
    "for a small random perturbation $\\delta$, for a given $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkcjac(z,delta):\n",
    "    cpert = c(z+delta)\n",
    "    c = c(z)\n",
    "    cjac_delta = np.dot(np.transpose(gradc(z)), delta)\n",
    "    n1 = np.linalg.norm(cpert - c - cjac_delta)\n",
    "    n2 = np.linalg.norm(delta)\n",
    "    if n1/n2 < 0.01:\n",
    "        return true\n",
    "    return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Python function, that given $z$, $\\lambda$ as an imput, yields $\\nabla_{zz} \\mathcal{L} (z, \\lambda)$.\n",
    "\n",
    "As shown in the report, the exact calculation of the Hessian of the Lagrangian give us :\n",
    "\n",
    "$$\n",
    "\\nabla_{zz} \\mathcal{L} (z, \\lambda) = \\begin{bmatrix} A & 0 \\\\ 0 & A \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where :\n",
    "\n",
    "$$\n",
    "A =\n",
    "    2 \\begin{pmatrix}\n",
    "    \\lambda_1+\\lambda_2 & -\\lambda_2 & & & (0)\\\\\n",
    "    -\\lambda_2 & \\lambda_2+\\lambda_3 & -\\lambda_3 & \\\\\n",
    "     & \\ddots & \\ddots & \\ddots \\\\\n",
    "      &  & \\ddots & \\ddots & -\\lambda_n \\\\\n",
    "     (0) & & & -\\lambda_n & \\lambda_n+\\lambda_{n+1}\n",
    "    \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hesslag(z, labda):\n",
    "    N=np.len(z)/2\n",
    "    A=np.zeros(N, N)\n",
    "    zero=np.zeros(N, N)\n",
    "    for i in range(N):\n",
    "        A[i,i] = labda[i] + labda[i+1]\n",
    "    for j in range(N-1):\n",
    "        temp = -labda[i+1]\n",
    "        A[i,i+1] = temp\n",
    "        A[i+1,i] = temp\n",
    "    A = 2*A\n",
    "    \n",
    "    hess=np.zeros(2*N,2*N)\n",
    "    hess[0:N , 0:N] = A\n",
    "    hess[0:N , N:2*N] = zero\n",
    "    hess[N:2*N , 0:N] = zero\n",
    "    hess[N:2*N , N:2*N] = A\n",
    "    return hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check that the double derivatives are correct, by checking that :\n",
    "\n",
    "$$\n",
    "\\frac{\\left\\| \\mathcal{L}(z+\\delta)- \\mathcal{L}(z) - \\nabla_{z} \\mathcal{L}(z) \\delta - \\delta^{T} \\nabla_{zz} \\mathcal{L}(z,\\lambda) \\delta \\right\\|}{\\left\\|\\delta\\ \\right\\|^2} \\leq 0.01\n",
    "$$\n",
    "\n",
    "for a small random perturbation $\\delta$, and for a given $z$ and $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkchess(z,delta, labda):\n",
    "    lagpert = lag(z+delta, labda)\n",
    "    lag = lag(z, labda)\n",
    "    gradlag_delta = np.dot(gradlag(z, labda), delta)\n",
    "    hesslag_delta = (np.transpose(delta)).dot(hesslag(z, labda).dot(delta))\n",
    "    \n",
    "    n1 = np.linalg.norm(lagpert - lag - gradlag_delta - hesslag_delta)\n",
    "    n2 = np.linalg.norm(delta)\n",
    "    if n1/(n2**2) < 0.1:\n",
    "        return true\n",
    "    return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "The problem is not convexe because even if the cost function is convexe, the admissble set is not. Indeed, the admissible set is defined by $c(z) = 0$.\n",
    "\n",
    "For instance if we take $a = 0, b = \\frac{L}{2}$, the minimum energie solution is of the form $ z = (x, y)$ (the chain is hanging down between the two fixations), and the solution $z = (x, -y)$ is also admisible, $c(x,y) = c(x -y)$ (it is the maximum energie solution, the chain is attracted by the top). But the mean vector of this two admissible solutions is $z = (x, 0)$ which is not admisble because it correspond to the a case where the chain is horizontal atached between the point (0,0) and (0, L/2), but its lenght is $L$, which is impossible in a lenght of $\\frac{L}{2}$.\n",
    "\n",
    "This prove taht the problem is non-convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "Now let's discuss about the qualification of the constraints. A necessary condition for the constraints to be qualified is to say that the Jacobian matrix of the constrains is surjective. In our case the Jacobain matrix of the constraints c is the transpose of the matrix $\\nabla^{T} c(z)$, which is to say the matrix \n",
    "$$\n",
    "\\nabla_{z} c(z) = 2 \n",
    "\\begin{bmatrix}\n",
    "x_1 & 0  & \\cdots & 0 & | & y_1 & 0  & \\cdots & 0 \\\\\n",
    "-(x_2 - x_1) & (x_2 - x_1) &  & \\vdots & | & -(y_2 - y_1) & (y_2 - y_1) &  & \\vdots\\\\\n",
    "0 & -(x_3-x_2) & \\ddots & 0 & | & 0 & -(y_3-y_2) & \\ddots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & (x_N-x_{N-1}) & | &\\vdots & \\vdots & \\ddots & (y_N-y_{N-1}) \\\\\n",
    "0 & 0 & \\cdots & -(x_N-a) & | & 0 & 0 & \\cdots & -(y_N-a)\\\\\n",
    "\\end{bmatrix}\\in \\mathbf{R}^{2 N \\times N+1}\n",
    "$$\n",
    "\n",
    "As shown in the report, the rank of this matrix is of rank $N+1$, and so it is surjective.\n",
    "\n",
    "Thus we know that we can apply the KKT conditions to this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "\n",
    "As shown in the report, the condition is :\n",
    "\n",
    "$$\n",
    "a^2 + b^2 \\le (NL)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "Let's solve this KKT optimality conditions problem with the Newton's method.\n",
    "\n",
    "Let $F(\\xi)=0$ represent the above non-linear system of equation, with $\\xi=(z, \\lambda)$ where :\n",
    "$F(\\xi): \\mathbf{R}^{2 N+N+1} \\rightarrow \\mathbf{R}^{2 N+N+1}, \\quad F(\\xi)=\\left[\\begin{array}{c}e+\\nabla_{z}^{\\top} c(z) \\lambda \\\\ c(z)\\end{array}\\right]$.\n",
    "\n",
    "So\n",
    "$$\n",
    "\\nabla_{\\xi} F(\\xi) \\in \\mathbf{R}^{2 N+N+1 \\times 2 N+N+1}, \\quad \\nabla_{\\xi} F(\\xi)=\\left[\\begin{array}{cc}\n",
    "\\nabla_{z}\\left(\\nabla_{z}^{\\top} c(z) \\lambda\\right) & \\nabla_{z}^{\\top} c(z) \\\\\n",
    "\\nabla_{z} c(z) & 0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "where one could verify that\n",
    "$$\n",
    "\\nabla_{z}\\left(\\nabla_{z}^{\\top} c(z) \\lambda\\right)=\\left[\\nabla_{x_{j}} \\sum_{k=1}^{N+1} \\nabla_{x_{i}} c_{k}(x, y) \\lambda_{k}\\right]_{i j} \\in \\mathbf{R}^{2 N \\times 2 N}=\\nabla_{z z} \\mathcal{L}(z, \\lambda)\n",
    "$$\n",
    "\n",
    "So  we can finally right that : \n",
    "$$\n",
    " \\nabla_{\\xi} F(\\xi)=\\left[\\begin{array}{cc}\n",
    "\\nabla_{z z} \\mathcal{L}(z, \\lambda) & \\nabla_{z}^{\\top} c(z) \\\\\n",
    "\\nabla_{z} c(z) & 0\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Let's first wright the Python function, that given $z$, $\\lambda$ as an imput, yields $\\nabla_{\\xi} F(\\xi)$, by reusing the previous functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fjac(z, labda):\n",
    "    N=np.len(z)/2\n",
    "\n",
    "    zero=np.zeros(N + 1, N + 1)\n",
    "    hesslag = hesslag(z, labda)\n",
    "    gradc = gradc(z)\n",
    "    \n",
    "    Fjac=np.zeros(3*N + 1, 3*N + 1)\n",
    "    Fjac[0:2*N , 0:2*N] = hesslag\n",
    "    Fjac[0:2*N , 2*N:3*N + 1] = gradc\n",
    "    Fjac[2*N:3*N + 1 , 0:2*N] = np.transpose(gradc)\n",
    "    Fjac[2*N:3*N + 1 , 2*N:3*N + 1] = zero\n",
    "    return Fjac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that the Jacobian matrix is invertible. We can now define a Newton's method algorithms that compute the Nexton's method for a given initial $\\xi^{0}$, a stopping error criterion $\\epsilon$, and a maximum number of iterations $N$.\n",
    "\n",
    "To do so, we'll need a function that yeilds the value of $F(\\xi)$ for a given $\\xi \\in \\mathbb{R}^{2N + N + 1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(z, labda):\n",
    "    F = np.zeros(3*N + 1)\n",
    "    gradlag = gradlag(z, labda)\n",
    "    c = c(z)\n",
    "    F[0:2*N] = gradlag\n",
    "    F[2*N:3*N + 1]\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewtonF(z, labda, eps, N):\n",
    "    k = 0\n",
    "    F = F(z, labda)\n",
    "    n=np.linalg.norm(F)\n",
    "    while(n>eps and k < N):\n",
    "        Fjac = Fjac(z, labda)\n",
    "        d = - np.linalg.solve(Fjac, F)\n",
    "        z = z + d[0:2*N]\n",
    "        labda = labda + d[2*N:3*N + 1]\n",
    "        F = F(z, labda)\n",
    "        n=np.linalg.norm(F)\n",
    "        k += 1\n",
    "    return z, labda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
