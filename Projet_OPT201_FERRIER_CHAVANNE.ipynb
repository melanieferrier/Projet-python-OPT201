{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical project in Python\n",
    "\n",
    "We will consider the problem of finding the static equilibrium of a chain formed by rigid bars in 2D.\n",
    "This will be found via an optimization problem with equality constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Python function that given $z$ as an imput, returns :\n",
    "\n",
    "$$\n",
    "c(z) = (c_1 (z) , \\ldots , c_{N+1} (z) ) = (l_{i}(x, y)^{2}-L^{2} = \\bigl(  (x_{i}-x_{i-1})^{2}+(y_{i}-y_{i-1})^{2}-L^{2} \\, , \\, i \\in [ 1 , \\ldots , N+1 ] \\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(z):\n",
    "    N=np.len(z)/2\n",
    "    x=z[0:N:1]\n",
    "    y=z[N:2*N:1]\n",
    "    c=np.zeros((N+1,1))\n",
    "    c[0] = (x[0])**2+(y[0])**2 - L**2\n",
    "    for i in range(1,N)\n",
    "        l=(x[i]-x[i-1])**2+(y[i]-y[i-1])**2 - L**2\n",
    "    c[N+1] = (a-x[N-1])**2+(b-y[N-1])**2 - L**2\n",
    "    return c\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Python function that given $z$ as an imput, return $\\sum_i y_i$.\n",
    "\n",
    "To do so, we compute a $e = (0 , \\ldots , 0 , 1 , \\ldots , 1)$ $2n$-array, and we comput the dot product of $e . z$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e(z):\n",
    "    N=np.len(z)/2\n",
    "    e=np.zeros(2*N)\n",
    "    e[N:2*N:1]=np.ones(N)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(z):\n",
    "    return np.dot(e(z), z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Python function that returns the lagrangian of the systeme, given $z$ and $\\lambda$ as an imput.\n",
    "\n",
    "To do so we write the Lagrangian as :\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(z, \\lambda)=e^{\\top} z+\\lambda^{\\top} c(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag(z,labda):\n",
    "    e=e(z)\n",
    "    return np.dot(np.transpose(e),z) + np.dot(np.transpose(labda),c(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Python function, that given $z$, $\\lambda$ as an imput, yields $\\nabla_z \\mathcal{L}(z, \\lambda)$.\n",
    "\n",
    "As shown in the report : \n",
    "$$\n",
    "\\nabla_{z} \\mathcal{L}(z, \\lambda)=e+\\nabla_{z}^{\\top} c(z) \\lambda \\in \\mathbf{R}^{2 N}\n",
    "$$\n",
    "\n",
    "where the Jacobian of c is :\n",
    "$$\n",
    "\\nabla_{z}^{\\top} c(z)= 2 \n",
    "\\left[\\begin{array}{ccc}\n",
    "x_1 & -(x_2 - x_1) & 0 & \\cdots & 0 \\\\\n",
    "0 & (x_2 - x_1) & -(x_3 - x_2) & \\cdots & 0 \\\\\n",
    "\\\\\n",
    "\\vdots & & \\ddots & \\ddots & \\vdots \\\\\n",
    "& & & & 0\\\\\n",
    "0 & \\cdots & 0 & (x_N - x_{N-1}) & -(x_N - a)\\\\\n",
    "\\hline y_1 & -(y_2 - y_1) & 0 & \\cdots & 0 \\\\\n",
    "0 & (y_2 - y_1) & -(y_3 - y_2) & \\cdots & 0 \\\\\n",
    "\\\\\n",
    "\\vdots & & \\ddots & \\ddots & \\vdots \\\\\n",
    "& & & & 0\\\\\n",
    "0 & \\cdots & 0 & (y_N - y_{N-1}) & -(y_N - a)\\\\\n",
    "\\end{array}\\right] \\in \\mathbf{R}^{2 N \\times N+1}\n",
    "$$\n",
    "\n",
    "First lets compute this Jacobian matrix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cjac(z):\n",
    "    N=np.len(z)/2\n",
    "    cjac=np.zeros(2*N, N+1)\n",
    "    \n",
    "    cjac[0,0] = 2*z[0]\n",
    "    cjac[N,0] = 2*z[N]\n",
    "    cjac[N-1,N] = 2*(z[N-1]-a)\n",
    "    cjac[2*n-1,N] = 2*(z[N-1]-b)\n",
    "    \n",
    "    for j in range(1,N):\n",
    "        temp = 2*(z[j]-z[j-1])\n",
    "        cjac[j,j-1] = -temp\n",
    "        cjac[j,j] = temp\n",
    "        temp = 2*(z[N+j]-z[N+j-1])\n",
    "        cjac[j,N+j-1] = -temp\n",
    "        cjac[j,N+j] = temp\n",
    "    return cjac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deduce the gradient of the Lagrangian by the quick vectorial calculation above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradlag(z,labda):\n",
    "    e=e(z)\n",
    "    cjac = cjac(z)\n",
    "    return e + np.dot(cjac,labda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function also check that the derivatives are correct, by checking that :\n",
    "$$\n",
    "\\frac{\\left\\|c(z+\\delta)-c(z)-\\nabla_{z} c(z) \\delta\\right\\|}{\\|\\delta\\|} \\leq 0.01\n",
    "$$\n",
    "\n",
    "for a small random perturbation $\\delta$, for a given $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkcjac(z,delta):\n",
    "    cpert = c(z+delta)\n",
    "    c = c(z)\n",
    "    cjac_delta = np.dot(cjac(z), delta)\n",
    "    n1 = np.linlag.norm(cpert - c - cjac_delta)\n",
    "    n2 = np.linlag.norm(delta)\n",
    "    if n1/n2 < 0.01:\n",
    "        return true\n",
    "    return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Python function, that given $z$, $\\lambda$ as an imput, yields $\\nabla_{zz} \\mathcal{L} (z, \\lambda)$.\n",
    "\n",
    "As shown in the report, the exact calculation of the Hessian of the Lagrangian give us :\n",
    "\n",
    "$$\n",
    "\\nabla_{zz} \\mathcal{L} (z, \\lambda) = \\begin{bmatrix} A & 0 \\\\ 0 & A \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where :\n",
    "\n",
    "$$\n",
    "A =\n",
    "    2 \\begin{pmatrix}\n",
    "    \\lambda_1+\\lambda_2 & -\\lambda_2 & & & (0)\\\\\n",
    "    -\\lambda_2 & \\lambda_2+\\lambda_3 & -\\lambda_3 & \\\\\n",
    "     & \\ddots & \\ddots & \\ddots \\\\\n",
    "      &  & \\ddots & \\ddots & -\\lambda_n \\\\\n",
    "     (0) & & & -\\lambda_n & \\lambda_n+\\lambda_{n+1}\n",
    "    \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hesslag(z, labda):\n",
    "    N=np.len(z)/2\n",
    "    A=np.zeros(N, N)\n",
    "    zero=np.zeros(N, N)\n",
    "    for i in range(N):\n",
    "        A[i,i] = labda[i] + labda[i+1]\n",
    "    for j in range(N-1):\n",
    "        temp = -labda[i+1]\n",
    "        A[i,i+1] = temp\n",
    "        A[i+1,i] = temp\n",
    "    A = 2*A\n",
    "    \n",
    "    hess=np.zeros(2*N,2*N)\n",
    "    hess[0:N , 0:N] = A\n",
    "    hess[0:N , N:2*N] = zero\n",
    "    hess[N:2*N , 0:N] = zero\n",
    "    hess[N:2*N , N:2*N] = A\n",
    "    return cjac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check that the double derivatives are correct, by checking that :\n",
    "\n",
    "$$\n",
    "\\frac{\\left\\| \\mathcal{L}(z+\\delta)- \\mathcal{L}(z) - \\nabla_{z} \\mathcal{L}(z) \\delta - \\delta^{T} \\nabla_{zz} \\mathcal{L}(z,\\lambda) \\delta \\right\\|}{\\left\\|\\delta\\ \\right\\|^2} \\leq 0.01\n",
    "$$\n",
    "\n",
    "for a small random perturbation $\\delta$, and for a given $z$ and $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkchess(z,delta, labda):\n",
    "    lagpert = lag(z+delta, labda)\n",
    "    lag = lag(z, labda)\n",
    "    gradlag_delta = np.dot(gradlag(z, labda), delta)\n",
    "    hesslag_delta = (np.transpose(delta)).dot(hesslag(z, labda).dot(delta))\n",
    "    \n",
    "    n1 = np.linlag.norm(lagpert - lag - gradlag_delta - hesslag_delta)\n",
    "    n2 = np.linlag.norm(delta)\n",
    "    if n1/(n2**2) < 0.1:\n",
    "        return true\n",
    "    return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "The problem is not convexe because even if the cost function is convexe, the admissble set is not. Indeed, the admissible set is defined by $c(z) = 0$.\n",
    "\n",
    "For instance if we take $a = 0, b = \\frac{L}{2}$, the minimum energie solution is of the form $ z = (x, y)$ (the chain is hanging down between the two fixations), and the solution $z = (x, -y)$ is also admisible, $c(x,y) = c(x -y)$ (it is the maximum energie solution, the chain is attracted by the top). But the mean vector of this two admissible solutions is $z = (x, 0)$ which is not admisble because it correspond to the a case where the chain is horizontal atached between the point (0,0) and (0, L/2), but its lenght is $L$, which is impossible in a lenght of $\\frac{L}{2}$.\n",
    "\n",
    "This prove taht the problem is non-convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
